import pyautogui
import time
from PIL import Image, ImageChops
import numpy as np
from gpt4all import GPT4All
from paddleocr import PaddleOCR
import re
import pyperclip
import cv2

# GPT ëª¨ë¸ ë¡œë”©
model = GPT4All(
    model_path="./models",
    # model_name="EEVE-Korean-Instruct-7B-v2.0-Preview.Q8_0",
    model_name="llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M",
    device="cuda",
    n_threads=8,
    allow_download=False,
)

# PaddleOCR ì´ˆê¸°í™” (í•œë²ˆë§Œ ë¡œë“œ)
ocr = PaddleOCR(lang="korean", use_angle_cls=False)

# ìº¡ì²˜ ì˜ì—­ ì„¤ì • (ì¹´í†¡ì°½ ë©”ì‹œì§€ ì˜ì—­)
CAPTURE_REGION = (1600, 780, 300, 170)


def capture_chat():
    """í™”ë©´ì˜ íŠ¹ì • ì˜ì—­ì„ ìº¡ì²˜í•©ë‹ˆë‹¤"""
    screenshot = pyautogui.screenshot(region=CAPTURE_REGION)
    screenshot.save("last_capture.png")
    return screenshot


def is_different(img1, img2, threshold=1000):
    """ë‘ ì´ë¯¸ì§€ ê°„ì˜ ì°¨ì´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤ (ì„ê³„ê°’ ì´ìƒì´ë©´ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ íŒë‹¨)"""
    diff = ImageChops.difference(img1, img2)
    diff_array = np.array(diff)
    diff_sum = np.sum(diff_array)
    return diff_sum > threshold


def extract_text_with_paddle(image_path):
    """PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í°ìƒ‰ ë§í’ì„ ë§Œ)"""
    # ì´ë¯¸ì§€ ì½ê¸°
    img = cv2.imread(image_path)

    # BGR â†’ HSV ë³€í™˜
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # í°ìƒ‰ ë²”ìœ„ ì„¤ì • (ì±„ë„ ë‚®ê³  ë°ê¸° ë†’ìŒ)
    lower_white = np.array([0, 0, 200])
    upper_white = np.array([180, 40, 255])

    # í°ìƒ‰ ë§ˆìŠ¤í¬ ìƒì„±
    mask = cv2.inRange(hsv, lower_white, upper_white)

    # ë§ˆìŠ¤í¬ëœ í°ìƒ‰ ì˜ì—­ë§Œ ì¶”ì¶œ
    white_only = cv2.bitwise_and(img, img, mask=mask)

    # ì €ì¥ (ë””ë²„ê¹…ìš©)
    cv2.imwrite("filtered_white_only.png", white_only)

    # OCR ì…ë ¥ì„ ìœ„í•´ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(white_only, cv2.COLOR_BGR2GRAY)

    # í•„ìš” ì‹œ ì„ê³„ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
    # _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)

    # OCR ì‹¤í–‰
    result = ocr.ocr(gray, cls=False)

    if not result or not result[0]:
        return ""

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    text_parts = [line[1][0] for line in result[0]]
    full_text = " ".join(text_parts).strip()

    # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±° (ìˆ«ì ì œì™¸)
    clean_text = re.sub(r"[^\sA-Za-zê°€-í£0-9.?!,]", "", full_text)
    clean_text = re.sub(r"\s+", " ", clean_text).strip()

    print(f"ì›ë³¸ OCR ê²°ê³¼: {text_parts}")
    print(f"ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {clean_text}")

    return clean_text


# def extract_text_with_paddle(image_path):
#     """PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
#     result = ocr.ocr(image_path, cls=False)

#     # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
#     if not result or not result[0]:
#         return ""

#     # ê°ì§€ëœ ëª¨ë“  í…ìŠ¤íŠ¸ ê²°í•©
#     text_parts = []
#     for line in result[0]:
#         text_parts.append(line[1][0])  # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ

#     # í…ìŠ¤íŠ¸ ì •ë¦¬
#     full_text = " ".join(text_parts).strip()
#     # í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì¼ë¶€ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€
#     # clean_text = re.sub(r"[^\w\s.?!,ê°€-í£]", "", full_text)
#     clean_text = re.sub(r"[^\sA-Za-zê°€-í£.?!,]", "", full_text)
#     # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¹˜í™˜
#     clean_text = re.sub(r"\s+", " ", clean_text).strip()

#     print(f"ì›ë³¸ OCR ê²°ê³¼: {text_parts}")
#     print(f"ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {clean_text}")

#     return clean_text


def generate_response(prompt):
    """GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    instruction = (
        "ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìµœëŒ€í•œ 100ì ì´í•˜ë¡œ ìµœëŒ€í•œ ì§§ê²Œ ë§ í•´ì¤˜. ì¶”ê°€ì§ˆë¬¸ ê¸ˆì§€. "
        f"ì§ˆë¬¸: {prompt}"
    )
    print(f"í”„ë¡¬í”„íŠ¸: {instruction}")

    with model.chat_session():
        response = model.generate(
            prompt=instruction,
            max_tokens=128,
        )
        response = response.strip()
        send_to_kakao(response)
    return True


def send_to_kakao(response):
    """ì¹´ì¹´ì˜¤í†¡ì— ì‘ë‹µ ì „ì†¡ (í´ë¦½ë³´ë“œ ì‚¬ìš©)"""
    # ì‘ë‹µì„ í´ë¦½ë³´ë“œì— ë³µì‚¬
    pyperclip.copy(response)

    # ë©”ì‹œì§€ ì°½ì— í¬ì»¤ìŠ¤
    # pyautogui.click(CAPTURE_REGION[0] + CAPTURE_REGION[2]//2,
    #                CAPTURE_REGION[1] + CAPTURE_REGION[3] + 50)

    # ë¶™ì—¬ë„£ê¸° ë‹¨ì¶•í‚¤ ì‚¬ìš© (Ctrl+V)
    pyautogui.hotkey("ctrl", "v")
    time.sleep(0.5)  # ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€
    pyautogui.press("enter")


def main():
    print("ğŸ”„ ì¹´ì¹´ì˜¤í†¡ ê°ì§€ ì‹œì‘ (5ì´ˆë§ˆë‹¤ í™•ì¸)")

    prev_img = capture_chat()
    prev_text = extract_text_with_paddle("last_capture.png")
    print(f"ì´ˆê¸° ìƒíƒœ: {prev_text}")

    last_response_time = 0  # ë§ˆì§€ë§‰ ì‘ë‹µ ì‹œê°„
    min_response_interval = 5  # ìµœì†Œ ì‘ë‹µ ê°„ê²©(ì´ˆ)

    while True:
        try:
            time.sleep(5)

            curr_img = capture_chat()

            if is_different(prev_img, curr_img):
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                curr_text = extract_text_with_paddle("last_capture.png")

                # ì´ë¯¸ì§€ëŠ” ë‹¬ë¼ë„ í…ìŠ¤íŠ¸ê°€ ê°™ìœ¼ë©´ ë¬´ì‹œ
                if curr_text != prev_text and curr_text:
                    print(f"ğŸ“© ìƒˆë¡œìš´ ë©”ì‹œì§€: {curr_text}")

                    # í•œê¸€ ë¬¸ìê°€ ìˆëŠ”ì§€ í™•ì¸
                    has_korean = any(
                        ord(c) >= ord("ê°€") and ord(c) <= ord("í£") for c in curr_text
                    )

                    # ì‘ë‹µ ê°„ê²© í™•ì¸ (ë„ˆë¬´ ë¹ ë¥¸ ì‘ë‹µ ë°©ì§€)
                    current_time = time.time()
                    enough_time_passed = (
                        current_time - last_response_time
                    ) > min_response_interval

                    if has_korean and enough_time_passed:
                        # GPT ì‘ë‹µ ìƒì„±
                        generate_response(curr_text)
                        # print(f"ğŸ¤– GPT ì‘ë‹µ: {reply}")

                        # ì‘ë‹µ ì „ì†¡
                        # send_to_kakao(reply)

                        # ë§ˆì§€ë§‰ ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
                        last_response_time = current_time
                    elif not has_korean:
                        print("âš ï¸ í•œê¸€ì´ ì—†ëŠ” ë©”ì‹œì§€ì…ë‹ˆë‹¤")
                    elif not enough_time_passed:
                        print("â±ï¸ ì‘ë‹µ ê°„ê²©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")

                    prev_text = curr_text

                prev_img = curr_img
            else:
                print("â³ ë³€í™” ì—†ìŒ")

        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            time.sleep(1)


if __name__ == "__main__":
    main()
